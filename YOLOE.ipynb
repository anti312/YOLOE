{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-xiQ5LImtXw"
      },
      "outputs": [],
      "source": [
        "# Download Dependencies\n",
        "\n",
        "!pip install git+https://github.com/THU-MIG/yoloe.git#subdirectory=third_party/CLIP\n",
        "!pip install git+https://github.com/THU-MIG/yoloe.git#subdirectory=third_party/ml-mobileclip\n",
        "!pip install git+https://github.com/THU-MIG/yoloe.git#subdirectory=third_party/lvis-api\n",
        "!pip install git+https://github.com/THU-MIG/yoloe.git\n",
        "\n",
        "!wget https://docs-assets.developer.apple.com/ml-research/datasets/mobileclip/mobileclip_blt.pt\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "hf_hub_download(repo_id=\"jameslahm/yoloe\", filename=\"yoloe-11s-seg.pt\", local_dir='.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the YOLOE model from the ultralytics library\n",
        "from ultralytics import YOLOE\n",
        "\n",
        "# Load the YOLOE model\n",
        "model = YOLOE(\"yoloe-11s-seg.pt\")\n",
        "\n",
        "# Define the class names that the model will recognize\n",
        "names = [\"crashed car\"]\n",
        "model.set_classes(names, model.get_text_pe(names))\n"
      ],
      "metadata": {
        "id": "2JXPDgdhnsZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Convert bounding box from xywhn format (normalized center coordinates) to xyxy format (absolute coordinates)\n",
        "def xywhn_to_xyxy(bbox, img_width, img_height):\n",
        "    x_c, y_c, w, h = bbox\n",
        "    x1 = (x_c - w / 2) * img_width\n",
        "    y1 = (y_c - h / 2) * img_height\n",
        "    x2 = (x_c + w / 2) * img_width\n",
        "    y2 = (y_c + h / 2) * img_height\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "# Compute IoU between two bounding boxes\n",
        "def compute_iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "\n",
        "    boxAArea = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n",
        "    boxBArea = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n",
        "\n",
        "    iou = interArea / (boxAArea + boxBArea - interArea + 1e-6)  # Small epsilon to avoid division by zero\n",
        "    return iou\n",
        "\n",
        "\n",
        "dataset_folder = \"/content/dataset\"\n",
        "annotations_folder = \"/content/dataset/annotations\"\n",
        "\n",
        "IOU_THRESHOLD = 0.5\n",
        "total_pred = 0  # Count of all predicted boxes\n",
        "all_ious = []   # List to store IoUs for valid matches\n",
        "\n",
        "# Iterate through the images in the dataset folder\n",
        "for filename in os.listdir(dataset_folder):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        image_path = os.path.join(dataset_folder, filename)  # Full path to the image file\n",
        "        image = Image.open(image_path)\n",
        "        width, height = image.size\n",
        "\n",
        "        # Make predictions on the image using the model (set confidence threshold to 0.26)\n",
        "        results = model.predict(image_path, conf=0.26)\n",
        "        pred_boxes = results[0].boxes.xywhn.cpu().numpy()  # Predicted bounding boxes (xywhn format)\n",
        "        results[0].show()\n",
        "\n",
        "        # Load the ground truth annotations for the current image\n",
        "        annotation_path = os.path.join(annotations_folder, os.path.splitext(filename)[0] + \".txt\")\n",
        "        if not os.path.exists(annotation_path):\n",
        "            print(f\"No annotation for {filename}\")\n",
        "            continue\n",
        "\n",
        "        with open(annotation_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "        gt_boxes = [list(map(float, line.strip().split()[1:])) for line in lines]  # Extract ground truth bounding boxes\n",
        "\n",
        "        # Convert both predicted and ground truth boxes to xyxy format\n",
        "        pred_xyxy = [xywhn_to_xyxy(box, width, height) for box in pred_boxes]\n",
        "        total_pred += len(pred_xyxy)\n",
        "        gt_xyxy = [xywhn_to_xyxy(box, width, height) for box in gt_boxes]\n",
        "\n",
        "        matched_gt = set()  # Set to keep track of matched ground truth boxes\n",
        "\n",
        "        # Compare predicted boxes with ground truth boxes\n",
        "        for i, pbox in enumerate(pred_xyxy):\n",
        "            best_iou = 0\n",
        "            best_j = -1\n",
        "            for j, gbox in enumerate(gt_xyxy):\n",
        "                if j in matched_gt:\n",
        "                    continue\n",
        "                iou = compute_iou(pbox, gbox)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_j = j\n",
        "\n",
        "            # Check if the best IoU is above the threshold\n",
        "            if best_iou >= IOU_THRESHOLD:\n",
        "                all_ious.append(best_iou)\n",
        "                matched_gt.add(best_j)\n",
        "                print(f\"{filename} - Match: Pred {i} ‚Üî GT {best_j} | IoU: {best_iou:.4f}\")\n",
        "            else:\n",
        "                print(f\"{filename} - Pred {i} ‚Üí No match (max IoU = {best_iou:.4f})\")\n",
        "\n",
        "# Calculate and print the mean IoU across all matches\n",
        "if all_ious:\n",
        "    mean_iou = sum(all_ious) / total_pred\n",
        "    print(f\"\\nüìä Mean IoU over all matches: {mean_iou:.4f} (with {total_pred} predictions and {len(all_ious)} matches)\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No valid bounding box matches found.\")\n"
      ],
      "metadata": {
        "id": "wrQA1q4IOvfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model without IoU calculation\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "dataset_folder = \"/content/dataset\"\n",
        "for filename in os.listdir(dataset_folder):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(dataset_folder, filename)\n",
        "            results = model.predict(image_path)\n",
        "            results[0].show()"
      ],
      "metadata": {
        "id": "RGigkqb9MzIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renove dataset folder\n",
        "!rm -rf /content/dataset"
      ],
      "metadata": {
        "id": "oUQcfpcijHSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}